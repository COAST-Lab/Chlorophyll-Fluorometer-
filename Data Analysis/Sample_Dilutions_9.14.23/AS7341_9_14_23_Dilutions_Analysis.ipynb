{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AS7341 8.22.23 Dillution Tests\n",
    "This is an analysis of the AS7341 8.22.23 Dilution Tests. This file contains the code for each of the analysis performed on the 128x Gain, 256x Gain and 512x Gain dilution tests complete with confidence intervals, uncertainty percentages, RSME and R2 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95% Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 512x Gain, 700ms Integration Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entire Dataset:\n",
      "95% Confidence Interval for F8 (Raw): 75.1315 to 96.9403\n",
      "Range of Uncertainty (95% CI Width) for Entire Dataset: 21.8088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress, t\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import math\n",
    "\n",
    "# Replace with the actual file path\n",
    "file_path = \"/Users/jessiewynne/chla_fluorometer/AS7341 Dilutuions 9.14.23/512x_700ms_2.csv\"\n",
    "# Read the CSV file without skipping any rows\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Filter out rows where the 'Test' column is 'test'\n",
    "df = df[df['Test'].str.lower() != 'test']\n",
    "\n",
    "# Convert 'F8 (Raw)' column to numeric values\n",
    "df['F8 (Raw)'] = pd.to_numeric(df['F8 (Raw)'], errors='coerce')\n",
    "\n",
    "# Get unique test categories (dilution values) in the order of appearance\n",
    "categories = df['Test'].unique()\n",
    "\n",
    "# Create a dictionary to store the 'F8 (Raw)' values for each category (dilution)\n",
    "category_f8_raw_dict = {}\n",
    "\n",
    "# Create dictionaries to store confidence intervals and ranges of uncertainty\n",
    "confidence_intervals = {}\n",
    "\n",
    "# Calculate the mean and standard deviation for the entire dataset for 'F8 (Raw)' data\n",
    "dataset_f8_raw_mean = df['F8 (Raw)'].mean()\n",
    "dataset_f8_raw_std = df['F8 (Raw)'].std()\n",
    "\n",
    "# Calculate the sample size for the entire dataset\n",
    "dataset_sample_size = len(df['F8 (Raw)'])\n",
    "\n",
    "# Calculate the standard error for the entire dataset's mean\n",
    "dataset_standard_error = dataset_f8_raw_std / np.sqrt(dataset_sample_size)\n",
    "\n",
    "# Calculate the margin of error using the t-distribution\n",
    "confidence_level = 0.95\n",
    "margin_of_error = t.ppf((1 + confidence_level) / 2, dataset_sample_size - 1) * dataset_standard_error\n",
    "\n",
    "# Calculate the confidence interval for the entire dataset's mean\n",
    "confidence_interval = (dataset_f8_raw_mean - margin_of_error, dataset_f8_raw_mean + margin_of_error)\n",
    "# Calculate the range of uncertainty (95% CI width) for the entire dataset\n",
    "uncertainty_range = confidence_interval[1] - confidence_interval[0]\n",
    "\n",
    "# Print the confidence interval and range of uncertainty for the entire dataset\n",
    "print(\"\\nEntire Dataset:\")\n",
    "print(f\"95% Confidence Interval for F8 (Raw): {confidence_interval[0]:.4f} to {confidence_interval[1]:.4f}\")\n",
    "print(f\"Range of Uncertainty (95% CI Width) for Entire Dataset: {uncertainty_range:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 256x Gain, 700ms Integration Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entire Dataset:\n",
      "95% Confidence Interval for F8 (Raw): 42.0202 to 53.6763\n",
      "Range of Uncertainty (95% CI Width) for Entire Dataset: 11.6561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace with the actual file path\n",
    "file_path = \"/Users/jessiewynne/chla_fluorometer/AS7341 Dilutuions 9.14.23/256x_700ms.csv\"\n",
    "# Read the CSV file without skipping any rows\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Filter out rows where the 'Test' column is 'test'\n",
    "df = df[df['Test'].str.lower() != 'test']\n",
    "\n",
    "# Convert 'F8 (Raw)' column to numeric values\n",
    "df['F8 (Raw)'] = pd.to_numeric(df['F8 (Raw)'], errors='coerce')\n",
    "\n",
    "# Get unique test categories (dilution values) in the order of appearance\n",
    "categories = df['Test'].unique()\n",
    "\n",
    "# Create a dictionary to store the 'F8 (Raw)' values for each category (dilution)\n",
    "category_f8_raw_dict = {}\n",
    "\n",
    "# Create dictionaries to store confidence intervals and ranges of uncertainty\n",
    "confidence_intervals = {}\n",
    "\n",
    "# Calculate the mean and standard deviation for the entire dataset for 'F8 (Raw)' data\n",
    "dataset_f8_raw_mean = df['F8 (Raw)'].mean()\n",
    "dataset_f8_raw_std = df['F8 (Raw)'].std()\n",
    "\n",
    "# Calculate the sample size for the entire dataset\n",
    "dataset_sample_size = len(df['F8 (Raw)'])\n",
    "\n",
    "# Calculate the standard error for the entire dataset's mean\n",
    "dataset_standard_error = dataset_f8_raw_std / np.sqrt(dataset_sample_size)\n",
    "\n",
    "# Calculate the margin of error using the t-distribution\n",
    "confidence_level = 0.95\n",
    "margin_of_error = t.ppf((1 + confidence_level) / 2, dataset_sample_size - 1) * dataset_standard_error\n",
    "\n",
    "# Calculate the confidence interval for the entire dataset's mean\n",
    "confidence_interval = (dataset_f8_raw_mean - margin_of_error, dataset_f8_raw_mean + margin_of_error)\n",
    "# Calculate the range of uncertainty (95% CI width) for the entire dataset\n",
    "uncertainty_range = confidence_interval[1] - confidence_interval[0]\n",
    "\n",
    "# Print the confidence interval and range of uncertainty for the entire dataset\n",
    "print(\"\\nEntire Dataset:\")\n",
    "print(f\"95% Confidence Interval for F8 (Raw): {confidence_interval[0]:.4f} to {confidence_interval[1]:.4f}\")\n",
    "print(f\"Range of Uncertainty (95% CI Width) for Entire Dataset: {uncertainty_range:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the CI interval width increases as the gain increases. This could indicate that the as the gain increases the variability of chlorophyll measurements increases. This could be desireable as an increase in variability/range of chlorophyll measurements could lead to increase in sensitivity of the sensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512 Gain, 700ms Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \n",
      "0.0\n",
      "10.333333333333334 mean value\n",
      "0.30249507099101003 standard error\n",
      "1.2833778958394957 standard deviation\n",
      "\n",
      "0.25 \n",
      "0.25\n",
      "9.11111111111111 mean value\n",
      "0.290243180538229 standard error\n",
      "1.2313975269103985 standard deviation\n",
      "\n",
      "0.50 \n",
      "0.50\n",
      "18.27777777777778 mean value\n",
      "0.3597889319121795 standard error\n",
      "1.5264551613058026 standard deviation\n",
      "\n",
      "0.75 \n",
      "0.75\n",
      "24.88888888888889 mean value\n",
      "0.24103384202072908 standard error\n",
      "1.0226199851298272 standard deviation\n",
      "\n",
      "2.0 \n",
      "2.0\n",
      "30.0 mean value\n",
      "0.40422604172722165 standard error\n",
      "1.7149858514250884 standard deviation\n",
      "\n",
      "4.0 \n",
      "4.0\n",
      "49.21052631578947 mean value\n",
      "0.31137262016313766 standard error\n",
      "1.3572417850765923 standard deviation\n",
      "\n",
      "6.0 \n",
      "6.0\n",
      "54.36842105263158 mean value\n",
      "0.3172480933337741 standard error\n",
      "1.382852378872881 standard deviation\n",
      "\n",
      "8.0 \n",
      "8.0\n",
      "66.89473684210526 mean value\n",
      "0.24054928422459798 standard error\n",
      "1.0485300208760655 standard deviation\n",
      "\n",
      "10.0 \n",
      "10.0\n",
      "75.10526315789474 mean value\n",
      "0.31432408538892836 standard error\n",
      "1.3701069237311885 standard deviation\n",
      "\n",
      "20.0 \n",
      "20.0\n",
      "147.33333333333334 mean value\n",
      "0.2914915440650688 standard error\n",
      "1.2366938848016846 standard deviation\n",
      "\n",
      "30.0 \n",
      "30.0\n",
      "194.0 mean value\n",
      "0.2556549962824568 standard error\n",
      "1.0846522890932808 standard deviation\n",
      "\n",
      "40.0 \n",
      "40.0\n",
      "208.44444444444446 mean value\n",
      "0.33550490895975427 standard error\n",
      "1.4234267774809048 standard deviation\n",
      "\n",
      "50.0 \n",
      "50.0\n",
      "298.1111111111111 mean value\n",
      "0.4636378523128941 standard error\n",
      "1.9670488163112865 standard deviation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Mean, SD and Error\n",
    "# Replace with the actual file path\n",
    "file_path = \"/Users/jessiewynne/chla_fluorometer/AS7341 Dilutuions 9.14.23/512x_700ms_2.csv\"\n",
    "# Read the CSV file without skipping any rows\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Filter out rows where the 'Test' column is 'test'\n",
    "df = df[df['Test'].str.lower() != 'test']\n",
    "\n",
    "# Convert 'F8 (Raw)' column to numeric values\n",
    "df['F8 (Raw)'] = pd.to_numeric(df['F8 (Raw)'], errors='coerce')\n",
    "# Get unique test categories in the order of appearance\n",
    "categories = df['Test'].unique()\n",
    "\n",
    "# Create a dictionary to store the 'F8 (Raw)' values for each category\n",
    "category_f8_raw_dict = {}\n",
    "# Store unique x-values and their corresponding data points\n",
    "x_values = []\n",
    "y_values = []\n",
    "std_devs = []\n",
    "for category in categories:\n",
    "    # Exclude the first data point from each category\n",
    "    category_df = df[df['Test'] == category][1:]\n",
    "    category_f8_raw_dict[category] = category_df['F8 (Raw)']\n",
    "\n",
    "  # Calculate the mean and standard deviation for 'F8 (Raw)' data in each category\n",
    "    category_f8_raw_mean = category_df['F8 (Raw)'].mean()\n",
    "    category_f8_raw_std = category_df['F8 (Raw)'].std()\n",
    "        # Calculate the sample size for each category\n",
    "    category_sample_size = len(category_df['F8 (Raw)'])\n",
    "    # Calculate the standard error for each category's mean\n",
    "    category_standard_error = category_f8_raw_std / np.sqrt(category_sample_size)\n",
    "\n",
    "    print(f\"{category} \")\n",
    "    print(f\"{category}\")\n",
    "    print(category_f8_raw_mean, \"mean value\")\n",
    "    print(category_standard_error, \"standard error\")\n",
    "    print(category_f8_raw_std, \"standard deviation\")\n",
    "    print()\n",
    "        # Check \n",
    "\n",
    "    try:\n",
    "        x_value = float(category)\n",
    "        x_values.append(x_value)\n",
    "        y_values.append(category_f8_raw_mean)\n",
    "        std_devs.append(category_f8_raw_std)\n",
    "    except ValueError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 256 Gain, 700ms Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \n",
      "0.0\n",
      "6.166666666666667 mean value\n",
      "0.1457457720325344 standard error\n",
      "0.6183469424008423 standard deviation\n",
      "\n",
      "0.25 \n",
      "0.25\n",
      "11.055555555555555 mean value\n",
      "0.17096844914416118 standard error\n",
      "0.7253576985527025 standard deviation\n",
      "\n",
      "0.50 \n",
      "0.50\n",
      "8.222222222222221 mean value\n",
      "0.172553971012341 standard error\n",
      "0.7320844981409595 standard deviation\n",
      "\n",
      "0.75 \n",
      "0.75\n",
      "9.391304347826088 mean value\n",
      "1.2865051018991644 standard error\n",
      "6.169861722590655 standard deviation\n",
      "\n",
      "2.0 \n",
      "2.0\n",
      "22.0 mean value\n",
      "0.19802950859533489 standard error\n",
      "0.8401680504168059 standard deviation\n",
      "\n",
      "4.0 \n",
      "4.0\n",
      "27.333333333333332 mean value\n",
      "0.16169041669088868 standard error\n",
      "0.6859943405700354 standard deviation\n",
      "\n",
      "6.0 \n",
      "6.0\n",
      "25.0 mean value\n",
      "0.20232565955562798 standard error\n",
      "0.8819171036881969 standard deviation\n",
      "\n",
      "8.0 \n",
      "8.0\n",
      "43.111111111111114 mean value\n",
      "0.15942890088431988 standard error\n",
      "0.6763995415945232 standard deviation\n",
      "\n",
      "10.0 \n",
      "10.0\n",
      "48.666666666666664 mean value\n",
      "0.18687063686046268 standard error\n",
      "0.8563488385776752 standard deviation\n",
      "\n",
      "20.0 \n",
      "20.0\n",
      "82.36842105263158 mean value\n",
      "0.13702192413871325 standard error\n",
      "0.5972647203701476 standard deviation\n",
      "\n",
      "30.0 \n",
      "30.0\n",
      "106.66666666666667 mean value\n",
      "0.19802950859533489 standard error\n",
      "0.8401680504168059 standard deviation\n",
      "\n",
      "40.0 \n",
      "40.0\n",
      "115.55555555555556 mean value\n",
      "0.2016633806606734 standard error\n",
      "0.8555852638929973 standard deviation\n",
      "\n",
      "50.0 \n",
      "50.0\n",
      "160.94444444444446 mean value\n",
      "0.1709684491441612 standard error\n",
      "0.7253576985527026 standard deviation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Mean, SD and Error\n",
    "# Replace with the actual file path\n",
    "file_path = \"/Users/jessiewynne/chla_fluorometer/AS7341 Dilutuions 9.14.23/256x_700ms.csv\"\n",
    "# Read the CSV file without skipping any rows\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Filter out rows where the 'Test' column is 'test'\n",
    "df = df[df['Test'].str.lower() != 'test']\n",
    "\n",
    "# Convert 'F8 (Raw)' column to numeric values\n",
    "df['F8 (Raw)'] = pd.to_numeric(df['F8 (Raw)'], errors='coerce')\n",
    "# Get unique test categories in the order of appearance\n",
    "categories = df['Test'].unique()\n",
    "\n",
    "# Create a dictionary to store the 'F8 (Raw)' values for each category\n",
    "category_f8_raw_dict = {}\n",
    "# Store unique x-values and their corresponding data points\n",
    "x_values = []\n",
    "y_values = []\n",
    "std_devs = []\n",
    "for category in categories:\n",
    "    # Exclude the first data point from each category\n",
    "    category_df = df[df['Test'] == category][1:]\n",
    "    category_f8_raw_dict[category] = category_df['F8 (Raw)']\n",
    "\n",
    "  # Calculate the mean and standard deviation for 'F8 (Raw)' data in each category\n",
    "    category_f8_raw_mean = category_df['F8 (Raw)'].mean()\n",
    "    category_f8_raw_std = category_df['F8 (Raw)'].std()\n",
    "        # Calculate the sample size for each category\n",
    "    category_sample_size = len(category_df['F8 (Raw)'])\n",
    "    # Calculate the standard error for each category's mean\n",
    "    category_standard_error = category_f8_raw_std / np.sqrt(category_sample_size)\n",
    "\n",
    "    print(f\"{category} \")\n",
    "    print(f\"{category}\")\n",
    "    print(category_f8_raw_mean, \"mean value\")\n",
    "    print(category_standard_error, \"standard error\")\n",
    "    print(category_f8_raw_std, \"standard deviation\")\n",
    "    print()\n",
    "        # Check \n",
    "\n",
    "    try:\n",
    "        x_value = float(category)\n",
    "        x_values.append(x_value)\n",
    "        y_values.append(category_f8_raw_mean)\n",
    "        std_devs.append(category_f8_raw_std)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sesnitivity Analysis\n",
    "\n",
    "The 512x Gain has a sensitivity of 0.50 ug/L, while the 256x Gain has a sensitivity of 0.75ug/L. Meaning that as the gain increases the sensitivity of the sensor increases as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512x Gain, 700ms Integration RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.364193578479265\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "# Replace with the actual file path\n",
    "file_path = \"/Users/jessiewynne/chla_fluorometer/AS7341 Dilutuions 9.14.23/512x_700ms_2.csv\"\n",
    "# Read the CSV file without skipping any rows\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Filter out rows where the 'Test' column is 'test'\n",
    "df = df[df['Test'].str.lower() != 'test']\n",
    "\n",
    "# Convert 'F8 (Raw)' column to numeric values\n",
    "df['F8 (Raw)'] = pd.to_numeric(df['F8 (Raw)'], errors='coerce')\n",
    "# Get unique test categories in the order of appearance\n",
    "categories = df['Test'].unique()\n",
    "\n",
    "# Create a dictionary to store the 'F8 (Raw)' values for each category\n",
    "category_f8_raw_dict = {}\n",
    "# Store unique x-values and their corresponding data points\n",
    "x_values = []\n",
    "y_values = []\n",
    "std_devs = []\n",
    "\n",
    "for category in categories:\n",
    "    # Exclude the first data point from each category\n",
    "    category_df = df[df['Test'] == category][1:]\n",
    "    category_f8_raw_dict[category] = category_df['F8 (Raw)']\n",
    "\n",
    "    # Calculate the mean and standard deviation for 'F8 (Raw)' data in each category\n",
    "    category_f8_raw_mean = category_df['F8 (Raw)'].mean()\n",
    "    category_f8_raw_std = category_df['F8 (Raw)'].std()\n",
    "\n",
    "    # Calculate the sample size for each category\n",
    "    category_sample_size = len(category_df['F8 (Raw)'])\n",
    "\n",
    "    try:\n",
    "        x_value = float(category)\n",
    "        x_values.append(x_value)\n",
    "        y_values.append(category_f8_raw_mean)\n",
    "        std_devs.append(category_f8_raw_std)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Calculate the line of best fit parameters (slope and intercept)\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x_values, y_values)\n",
    "\n",
    "def predict_values(x, slope, intercept):\n",
    "    return slope * x + intercept\n",
    "# Calculate R-squared and RMSE\n",
    "y_predicted = predict_values(np.array(x_values), slope, intercept)\n",
    "rmse = np.sqrt(mean_squared_error(y_values, y_predicted))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 256x Gain, 700ms Integration RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.922142169978342\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "# Replace with the actual file path\n",
    "file_path = \"/Users/jessiewynne/chla_fluorometer/AS7341 Dilutuions 9.14.23/256x_700ms.csv\"\n",
    "# Read the CSV file without skipping any rows\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Filter out rows where the 'Test' column is 'test'\n",
    "df = df[df['Test'].str.lower() != 'test']\n",
    "\n",
    "# Convert 'F8 (Raw)' column to numeric values\n",
    "df['F8 (Raw)'] = pd.to_numeric(df['F8 (Raw)'], errors='coerce')\n",
    "# Get unique test categories in the order of appearance\n",
    "categories = df['Test'].unique()\n",
    "\n",
    "# Create a dictionary to store the 'F8 (Raw)' values for each category\n",
    "category_f8_raw_dict = {}\n",
    "# Store unique x-values and their corresponding data points\n",
    "x_values = []\n",
    "y_values = []\n",
    "std_devs = []\n",
    "\n",
    "for category in categories:\n",
    "    # Exclude the first data point from each category\n",
    "    category_df = df[df['Test'] == category][1:]\n",
    "    category_f8_raw_dict[category] = category_df['F8 (Raw)']\n",
    "\n",
    "    # Calculate the mean and standard deviation for 'F8 (Raw)' data in each category\n",
    "    category_f8_raw_mean = category_df['F8 (Raw)'].mean()\n",
    "    category_f8_raw_std = category_df['F8 (Raw)'].std()\n",
    "\n",
    "    # Calculate the sample size for each category\n",
    "    category_sample_size = len(category_df['F8 (Raw)'])\n",
    "\n",
    "    try:\n",
    "        x_value = float(category)\n",
    "        x_values.append(x_value)\n",
    "        y_values.append(category_f8_raw_mean)\n",
    "        std_devs.append(category_f8_raw_std)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Calculate the line of best fit parameters (slope and intercept)\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x_values, y_values)\n",
    "\n",
    "def predict_values(x, slope, intercept):\n",
    "    return slope * x + intercept\n",
    "# Calculate R-squared and RMSE\n",
    "y_predicted = predict_values(np.array(x_values), slope, intercept)\n",
    "rmse = np.sqrt(mean_squared_error(y_values, y_predicted))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE Analysis\n",
    "\n",
    "The RMSE seems to increase as the Gain of the sensor increases, meaning as the Gain increases predicting the F8 values becomes more difficult. When looking at the F8 values in comparison to the line of best fit it appears that the F8 value for 40.0 ug/L is the main outliar compared to the line of best fit. This could be due to a possible error in the dilution value itself, since it is the only obvious outliar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512x Gain, 700ms Integration R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833749149962714\n"
     ]
    }
   ],
   "source": [
    "# R_Squared\n",
    "# Replace with the actual file path\n",
    "file_path = \"/Users/jessiewynne/chla_fluorometer/AS7341 Dilutuions 9.14.23/512x_700ms_2.csv\"\n",
    "# Read the CSV file without skipping any rows\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Filter out rows where the 'Test' column is 'test'\n",
    "df = df[df['Test'].str.lower() != 'test']\n",
    "\n",
    "# Convert 'F8 (Raw)' column to numeric values\n",
    "df['F8 (Raw)'] = pd.to_numeric(df['F8 (Raw)'], errors='coerce')\n",
    "# Get unique test categories in the order of appearance\n",
    "categories = df['Test'].unique()\n",
    "\n",
    "# Create a dictionary to store the 'F8 (Raw)' values for each category\n",
    "category_f8_raw_dict = {}\n",
    "# Store unique x-values and their corresponding data points\n",
    "x_values = []\n",
    "y_values = []\n",
    "std_devs = []\n",
    "\n",
    "for category in categories:\n",
    "    # Exclude the first data point from each category\n",
    "    category_df = df[df['Test'] == category][1:]\n",
    "    category_f8_raw_dict[category] = category_df['F8 (Raw)']\n",
    "\n",
    "    # Calculate the mean and standard deviation for 'F8 (Raw)' data in each category\n",
    "    category_f8_raw_mean = category_df['F8 (Raw)'].mean()\n",
    "    category_f8_raw_std = category_df['F8 (Raw)'].std()\n",
    "\n",
    "    # Calculate the sample size for each category\n",
    "    category_sample_size = len(category_df['F8 (Raw)'])\n",
    "\n",
    "    try:\n",
    "        x_value = float(category)\n",
    "        x_values.append(x_value)\n",
    "        y_values.append(category_f8_raw_mean)\n",
    "        std_devs.append(category_f8_raw_std)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Calculate the line of best fit parameters (slope and intercept)\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x_values, y_values)\n",
    "\n",
    "def predict_values(x, slope, intercept):\n",
    "    return slope * x + intercept\n",
    "# Calculate R-squared and RMSE\n",
    "y_predicted = predict_values(np.array(x_values), slope, intercept)\n",
    "rmse = np.sqrt(mean_squared_error(y_values, y_predicted))\n",
    "r_squared = r2_score(y_values, y_predicted)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 256x Gain, 700ms Integration R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978990299142044\n"
     ]
    }
   ],
   "source": [
    "# R_Squared\n",
    "# Replace with the actual file path\n",
    "file_path = \"/Users/jessiewynne/chla_fluorometer/AS7341 Dilutuions 9.14.23/256x_700ms.csv\"\n",
    "# Read the CSV file without skipping any rows\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Filter out rows where the 'Test' column is 'test'\n",
    "df = df[df['Test'].str.lower() != 'test']\n",
    "\n",
    "# Convert 'F8 (Raw)' column to numeric values\n",
    "df['F8 (Raw)'] = pd.to_numeric(df['F8 (Raw)'], errors='coerce')\n",
    "# Get unique test categories in the order of appearance\n",
    "categories = df['Test'].unique()\n",
    "\n",
    "# Create a dictionary to store the 'F8 (Raw)' values for each category\n",
    "category_f8_raw_dict = {}\n",
    "# Store unique x-values and their corresponding data points\n",
    "x_values = []\n",
    "y_values = []\n",
    "std_devs = []\n",
    "\n",
    "for category in categories:\n",
    "    # Exclude the first data point from each category\n",
    "    category_df = df[df['Test'] == category][1:]\n",
    "    category_f8_raw_dict[category] = category_df['F8 (Raw)']\n",
    "\n",
    "    # Calculate the mean and standard deviation for 'F8 (Raw)' data in each category\n",
    "    category_f8_raw_mean = category_df['F8 (Raw)'].mean()\n",
    "    category_f8_raw_std = category_df['F8 (Raw)'].std()\n",
    "\n",
    "    # Calculate the sample size for each category\n",
    "    category_sample_size = len(category_df['F8 (Raw)'])\n",
    "\n",
    "    try:\n",
    "        x_value = float(category)\n",
    "        x_values.append(x_value)\n",
    "        y_values.append(category_f8_raw_mean)\n",
    "        std_devs.append(category_f8_raw_std)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Calculate the line of best fit parameters (slope and intercept)\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x_values, y_values)\n",
    "\n",
    "def predict_values(x, slope, intercept):\n",
    "    return slope * x + intercept\n",
    "# Calculate R-squared and RMSE\n",
    "y_predicted = predict_values(np.array(x_values), slope, intercept)\n",
    "rmse = np.sqrt(mean_squared_error(y_values, y_predicted))\n",
    "r_squared = r2_score(y_values, y_predicted)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Analysis\n",
    "\n",
    "Both R2 values indicate that the change in F8 values correspond to the changing chlorophyll concentrations. The R2 value is slightly higher for the 512x Gain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Overall it appears that the increase in the integration time as well as the Gain value leads to a higher sensitivity of the sensor. This increase in the sensitivity of the sensor to 0.50ug/L reaches the goal established on 8.22.23 of achieving a sensitivity of 0.5 ug/L. The R2 values are similar to the dilution tests on 8.22.23, they are only slightly smaller. The RMSE values of these dilutions are quite high indicating that predicting the F8 values is difficult and that they at times do not follow the line of best fit. When looking at the F8 values in comparison to the line of best fit in both Gain values, there is one obvious outliar at 40.0 ug/L. Because there is a single outliar this could be due to a dilution error which could be contributing to the high RMSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Steps\n",
    "1. Due to the increased sensitivity, integration of a brighter LED or lense is not needed at this time\n",
    "2. Re-running the tests at 512x Gain with a 700ms integration time for 3-5 trials will be necessary to evaluate variability in the measurements \n",
    "3. Re-running these tests with new dilutions will be be necessary to evaluate if the 40.0ug/L F8 measurement is actually an outliar and see if a new dilution for this will decrease the RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
